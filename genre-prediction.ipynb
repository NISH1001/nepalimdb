{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data/nepali-movies.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>plot</th>\n",
       "      <th>rating</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "      <th>votes</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Documentary, Adventure, Drama</td>\n",
       "      <td>https://www.imdb.com/title/tt1999130/</td>\n",
       "      <td>A team of 20 elite Nepali climbers venture int...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99 min</td>\n",
       "      <td>Death Zone: Cleaning Mount Everest</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>https://www.imdb.com/title/tt7229666/</td>\n",
       "      <td>Chhakka Panja 2 continues with new story of Ra...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>138 min</td>\n",
       "      <td>Chhakka Panja 2</td>\n",
       "      <td>261.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>https://www.imdb.com/title/tt8393764/</td>\n",
       "      <td>When she learns about the worst condition of t...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>None</td>\n",
       "      <td>Chhakka Panja 3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>https://www.imdb.com/title/tt9812236/</td>\n",
       "      <td>Add a Plot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Love Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama, History</td>\n",
       "      <td>https://www.imdb.com/title/tt3700482/</td>\n",
       "      <td>After her husband's death, a girl is forced to...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Jhola</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           genre                               imdb_url  \\\n",
       "0  Documentary, Adventure, Drama  https://www.imdb.com/title/tt1999130/   \n",
       "1                  Comedy, Drama  https://www.imdb.com/title/tt7229666/   \n",
       "2                         Comedy  https://www.imdb.com/title/tt8393764/   \n",
       "3                 Drama, Romance  https://www.imdb.com/title/tt9812236/   \n",
       "4                 Drama, History  https://www.imdb.com/title/tt3700482/   \n",
       "\n",
       "                                                plot  rating  runtime  \\\n",
       "0  A team of 20 elite Nepali climbers venture int...     8.0   99 min   \n",
       "1  Chhakka Panja 2 continues with new story of Ra...     7.1  138 min   \n",
       "2  When she learns about the worst condition of t...     6.5     None   \n",
       "3                                         Add a Plot     NaN     None   \n",
       "4  After her husband's death, a girl is forced to...     7.6   90 min   \n",
       "\n",
       "                                title  votes  year  \n",
       "0  Death Zone: Cleaning Mount Everest   62.0  2018  \n",
       "1                     Chhakka Panja 2  261.0  2017  \n",
       "2                     Chhakka Panja 3   86.0  2018  \n",
       "3                        Love Station    NaN  2019  \n",
       "4                               Jhola  244.0  2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre        77\n",
       "imdb_url      0\n",
       "plot          0\n",
       "rating      533\n",
       "runtime     406\n",
       "title         0\n",
       "votes       533\n",
       "year          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['plot', 'genre']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A team of 20 elite Nepali climbers venture int...</td>\n",
       "      <td>Documentary, Adventure, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chhakka Panja 2 continues with new story of Ra...</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When she learns about the worst condition of t...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Add a Plot</td>\n",
       "      <td>Drama, Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After her husband's death, a girl is forced to...</td>\n",
       "      <td>Drama, History</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                plot  \\\n",
       "0  A team of 20 elite Nepali climbers venture int...   \n",
       "1  Chhakka Panja 2 continues with new story of Ra...   \n",
       "2  When she learns about the worst condition of t...   \n",
       "3                                         Add a Plot   \n",
       "4  After her husband's death, a girl is forced to...   \n",
       "\n",
       "                           genre  \n",
       "0  Documentary, Adventure, Drama  \n",
       "1                  Comedy, Drama  \n",
       "2                         Comedy  \n",
       "3                 Drama, Romance  \n",
       "4                 Drama, History  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot     0\n",
       "genre    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove data without any plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['plot'] == 'Add a Plot'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['plot'].str.contains(\"Add a Plot\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', ' <url> ', text)\n",
    "    text = re.sub(r'#+', ' <hashtag> ', text )\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', ' <user> ', text)\n",
    "    text = re.sub(r\"([A-Za-z]+)'s\", r\"\\1 is\", text)\n",
    "\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"don't\", \"do not \", text)\n",
    "    text = re.sub(r\"did't\", \"did not \", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not \", text)\n",
    "    text = re.sub(r\"wouldn't\", \"would not \", text)\n",
    "    text = re.sub(r\"hadn't\", \"had not \", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not \", text)\n",
    "    text = re.sub(r\"isn't\", \"is not \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "\n",
    "    text = re.sub(r\"dont\", \" do not\", text)\n",
    "    text = re.sub(r\"didnt\", \" did not\", text)\n",
    "    text = re.sub(r\"wont\", \" will not\", text)\n",
    "    text = re.sub(r\"cant\", \" can not\", text)\n",
    "\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' <number> ', text)\n",
    "    text = re.sub('\\s+url\\s+', ' <url> ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['plot_clean'] = df['plot'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "      <th>plot_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A team of 20 elite Nepali climbers venture int...</td>\n",
       "      <td>Documentary, Adventure, Drama</td>\n",
       "      <td>a team of &lt;number&gt; elite nepali climbers ventu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chhakka Panja 2 continues with new story of Ra...</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>chhakka panja &lt;number&gt; continues with new stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When she learns about the worst condition of t...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>when she learns about the worst condition of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After her husband's death, a girl is forced to...</td>\n",
       "      <td>Drama, History</td>\n",
       "      <td>after her husband is death a girl is forced to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>An excellent portrayal of a struggle of a comm...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>an excellent portrayal of a struggle of a comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                plot  \\\n",
       "0  A team of 20 elite Nepali climbers venture int...   \n",
       "1  Chhakka Panja 2 continues with new story of Ra...   \n",
       "2  When she learns about the worst condition of t...   \n",
       "4  After her husband's death, a girl is forced to...   \n",
       "5  An excellent portrayal of a struggle of a comm...   \n",
       "\n",
       "                           genre  \\\n",
       "0  Documentary, Adventure, Drama   \n",
       "1                  Comedy, Drama   \n",
       "2                         Comedy   \n",
       "4                 Drama, History   \n",
       "5                          Drama   \n",
       "\n",
       "                                          plot_clean  \n",
       "0  a team of <number> elite nepali climbers ventu...  \n",
       "1  chhakka panja <number> continues with new stor...  \n",
       "2  when she learns about the worst condition of t...  \n",
       "4  after her husband is death a girl is forced to...  \n",
       "5  an excellent portrayal of a struggle of a comm...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n",
    "Use TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "#     stop_words=stop_words,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['plot_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 7707)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Labels\n",
    "Since the data has multiple labels per movie plot, multi hot binarizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Documentary', ' Adventure', ' Drama'],\n",
       " ['Comedy', ' Drama'],\n",
       " ['Comedy'],\n",
       " ['Drama', ' History'],\n",
       " ['Drama'],\n",
       " ['Comedy', ' Drama'],\n",
       " ['Drama', ' Romance'],\n",
       " ['Drama'],\n",
       " ['Action', ' Drama'],\n",
       " ['Drama', ' Romance']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [genre.split(',') for genre in df['genre'].values]\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_hot = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = very_hot.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 41)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Action', ' Adventure', ' Animation', ' Biography', ' Comedy',\n",
       "       ' Crime', ' Drama', ' Family', ' Fantasy', ' History', ' Horror',\n",
       "       ' Music', ' Musical', ' Mystery', ' News', ' Reality-TV',\n",
       "       ' Romance', ' Sci-Fi', ' Short', ' Sport', ' Thriller', ' War',\n",
       "       ' Western', 'Action', 'Adventure', 'Animation', 'Biography',\n",
       "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Game-Show',\n",
       "       'History', 'Horror', 'Music', 'Musical', 'Reality-TV', 'Romance',\n",
       "       'Short', 'Thriller'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "very_hot.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultinomialNB(alpha=0.1)\n",
    "model = OneVsRestClassifier(MultinomialNB(alpha=0.1))\n",
    "# model = OneVsRestClassifier(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=0.1, class_prior=None,\n",
       "                                            fit_prior=True),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 3, 1, 2, 2, 3, 3, 2, 3, 3, 2, 2,\n",
       "       2, 2, 1, 2, 2, 1, 2, 0, 2, 1, 2, 2, 1, 2, 1, 2, 3, 2, 2, 2, 3, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 3, 3, 1, 3, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2,\n",
       "       2, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 3, 2, 1, 1, 2, 2, 3,\n",
       "       2, 3, 3, 1, 1, 1, 2, 3, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 3, 2,\n",
       "       1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 2, 2, 2, 1, 3, 2, 1, 1,\n",
       "       1, 2, 2, 1, 1, 2, 1, 2, 2, 3, 1, 1, 1, 2, 2, 3, 2, 2, 1, 1, 1, 1,\n",
       "       2, 3, 2, 3, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 3, 1, 2, 3,\n",
       "       1, 2, 2, 3, 2, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 3, 3, 2, 2, 2,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 2, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 3, 1, 3, 2, 1, 1, 1,\n",
       "       2, 1, 2, 1, 1, 2, 1, 3, 2, 3, 2, 2, 1, 1, 1, 2, 2, 3, 2, 3, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 3, 2, 2, 3, 2, 1, 1, 1, 3, 1, 2, 2,\n",
       "       1, 1, 1, 1, 1, 2, 2, 2, 1, 3, 2, 2, 1, 2, 3, 1, 3, 2, 1, 1, 2, 3,\n",
       "       1, 2, 1, 0, 3, 2, 2, 3, 2, 2, 1, 2, 2, 1, 2, 3, 2, 2, 3, 2, 2, 1,\n",
       "       2, 2, 3, 1, 1, 2, 3, 1, 3, 3, 1, 3, 2, 1, 1, 2, 2, 3, 2, 3, 3, 2,\n",
       "       1, 2, 2, 1, 3, 3, 2, 3, 3, 3, 2, 2, 3, 2, 1, 1, 3, 1, 3, 2, 3, 2,\n",
       "       1, 2, 2, 2, 2, 3, 2, 3, 2, 1, 1, 3, 2, 2, 2, 2, 2, 1, 3, 2, 3, 2,\n",
       "       3, 3, 2, 3, 3, 2, 2, 1, 2, 2, 1, 3, 1, 1, 3, 2, 3, 2, 2, 2])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[412,   0],\n",
       "        [  0,   4]],\n",
       "\n",
       "       [[399,   0],\n",
       "        [  0,  17]],\n",
       "\n",
       "       [[415,   0],\n",
       "        [  0,   1]],\n",
       "\n",
       "       [[406,   0],\n",
       "        [  0,  10]],\n",
       "\n",
       "       [[409,   0],\n",
       "        [  0,   7]],\n",
       "\n",
       "       [[410,   0],\n",
       "        [  0,   6]],\n",
       "\n",
       "       [[291,   0],\n",
       "        [  0, 125]],\n",
       "\n",
       "       [[398,   0],\n",
       "        [  0,  18]],\n",
       "\n",
       "       [[413,   0],\n",
       "        [  0,   3]],\n",
       "\n",
       "       [[405,   0],\n",
       "        [  1,  10]],\n",
       "\n",
       "       [[411,   0],\n",
       "        [  0,   5]],\n",
       "\n",
       "       [[409,   0],\n",
       "        [  0,   7]],\n",
       "\n",
       "       [[407,   0],\n",
       "        [  0,   9]],\n",
       "\n",
       "       [[405,   0],\n",
       "        [  0,  11]],\n",
       "\n",
       "       [[414,   0],\n",
       "        [  0,   2]],\n",
       "\n",
       "       [[415,   0],\n",
       "        [  0,   1]],\n",
       "\n",
       "       [[375,   0],\n",
       "        [  0,  41]],\n",
       "\n",
       "       [[413,   0],\n",
       "        [  0,   3]],\n",
       "\n",
       "       [[370,   0],\n",
       "        [  0,  46]],\n",
       "\n",
       "       [[413,   0],\n",
       "        [  0,   3]],\n",
       "\n",
       "       [[403,   0],\n",
       "        [  0,  13]],\n",
       "\n",
       "       [[414,   0],\n",
       "        [  0,   2]],\n",
       "\n",
       "       [[415,   0],\n",
       "        [  0,   1]],\n",
       "\n",
       "       [[388,   0],\n",
       "        [  0,  28]],\n",
       "\n",
       "       [[412,   0],\n",
       "        [  0,   4]],\n",
       "\n",
       "       [[412,   0],\n",
       "        [  0,   4]],\n",
       "\n",
       "       [[408,   0],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[382,   0],\n",
       "        [  1,  33]],\n",
       "\n",
       "       [[407,   0],\n",
       "        [  0,   9]],\n",
       "\n",
       "       [[326,   0],\n",
       "        [  0,  90]],\n",
       "\n",
       "       [[312,   0],\n",
       "        [  0, 104]],\n",
       "\n",
       "       [[414,   0],\n",
       "        [  0,   2]],\n",
       "\n",
       "       [[415,   0],\n",
       "        [  0,   1]],\n",
       "\n",
       "       [[414,   0],\n",
       "        [  0,   2]],\n",
       "\n",
       "       [[413,   0],\n",
       "        [  0,   3]],\n",
       "\n",
       "       [[415,   0],\n",
       "        [  0,   1]],\n",
       "\n",
       "       [[413,   0],\n",
       "        [  1,   2]],\n",
       "\n",
       "       [[415,   0],\n",
       "        [  0,   1]],\n",
       "\n",
       "       [[400,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[315,   0],\n",
       "        [  0, 101]],\n",
       "\n",
       "       [[411,   0],\n",
       "        [  0,   5]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"a man stalks a girl after while they fall in love\"\n",
    "text = \"a man falls in love with a girl from another country when she visits nepal\"\n",
    "text = process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7707)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = predictions == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Drama'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "very_hot.classes_.reshape(1, -1)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
